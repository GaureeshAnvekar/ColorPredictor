{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "color_predictor.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UBpSsE0wYAGg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fG2PWNA3YQwL",
        "colab_type": "code",
        "outputId": "87260d91-b03e-43af-b109-c68483964905",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1dc03aeb-5fb8-498d-9d1f-774291c7fdc4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1dc03aeb-5fb8-498d-9d1f-774291c7fdc4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving color-dev-data.csv to color-dev-data (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NaEKiFt-YaFk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8asX_w_jYl79",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#color_data_df = pd.read_csv(io.StringIO(uploaded[\"color-data-train.csv\"].decode(\"utf-8\")))\n",
        "#color_test_df = pd.read_csv(io.StringIO(uploaded[\"color-test-data.csv\"].decode(\"utf-8\")))\n",
        "color_dev_df = pd.read_csv(io.StringIO(uploaded[\"color-dev-data.csv\"].decode(\"utf-8\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6wuvfkOY8ku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loading dataset from color-data-train.csv. X_train has 4 features red,green,blue,text-color(0 for black,1 for white). Y_train has labels 0(\"Can't See) or 1(\"Can See\").\"\n",
        "Y_train = np.array(color_data_df[\"0.4\"])\n",
        "Y_train = np.float32(Y_train.T)\n",
        "Y_train = Y_train.reshape(1,Y_train.shape[0])             #shape of Y_train = (1,37587)\n",
        "X_train = np.array(color_data_df.iloc[:,:4])\n",
        "X_train = np.float32(X_train.T)                           #shape of X_train = (4,37587)\n",
        "\n",
        "#Normalizing features. Max value for red, green, blue features is 256, so divide each feature value by 256. For \"text-color\" feature only possible values are 0 or 1. So don't normalize this feature.\n",
        "X_train[:3,:] = X_train[:3,:]/256\n",
        "\n",
        "#Same for test set\n",
        "Y_test = np.array(color_test_df[\"0.4\"])\n",
        "Y_test = np.float32(Y_test.T)\n",
        "Y_test = Y_test.reshape(1,Y_test.shape[0])\n",
        "X_test = np.array(color_test_df.iloc[:,:4])\n",
        "X_test = np.float32(X_test.T)\n",
        "#Normalize test features\n",
        "X_test[:3,:] = X_test[:3,:]/256\n",
        "\n",
        "#Same for dev set\n",
        "Y_dev = np.array(color_dev_df[\"0.4\"])\n",
        "Y_dev = np.float32(Y_dev.T)\n",
        "Y_dev = Y_dev.reshape(1,Y_dev.shape[0])\n",
        "X_dev = np.array(color_dev_df.iloc[:,:4])\n",
        "X_dev = np.float32(X_dev.T)\n",
        "#Normalize dev features\n",
        "X_dev[:3,:] = X_dev[:3,:]/256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7lQ5_KtY-K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session.\n",
        "    \n",
        "    Arguments:\n",
        "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
        "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
        "    \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
        "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
        "    \"\"\"\n",
        "\n",
        "    X = tf.placeholder(\"float32\", [n_x, None])\n",
        "    Y = tf.placeholder(\"float32\", [n_y, None])\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxzK_pDRZWV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
        "                        W1 : [3, 4]  3 neurons in the first layer, 4 input features\n",
        "                        b1 : [3, 1]\n",
        "                        W2 : [1, 3]\n",
        "                        b2 : [1, 1]\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- a dictionary of tensors containing W1, b1, W2, b2\n",
        "    \"\"\"\n",
        "        \n",
        "    W1 = tf.get_variable(\"W1\", [3,4], initializer = tf.contrib.layers.xavier_initializer(), dtype=\"float32\")\n",
        "    b1 = tf.get_variable(\"b1\", [3,1], initializer = tf.zeros_initializer(), dtype=\"float32\")\n",
        "    W2 = tf.get_variable(\"W2\", [1,3], initializer = tf.contrib.layers.xavier_initializer(), dtype=\"float32\")\n",
        "    b2 = tf.get_variable(\"b2\", [1,1], initializer = tf.zeros_initializer(), dtype=\"float32\")\n",
        "    \n",
        "  \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    '''\n",
        "    \n",
        "    parameters = {'W1': tf.get_variable(\"W1\", initializer = tf.convert_to_tensor(np.array([[ 0.31035033, -0.7829059 , -0.41219217, -0.16607714],\n",
        "                [-1.3012043 , -3.715908  , -0.24158937,  5.1152887 ],\n",
        "                [  0.42639863,  4.409025  ,  0.26884907,  0.55255806  ]],\n",
        "                dtype=\"float32\"))),\n",
        "                'W2': tf.get_variable(\"W2\", initializer = tf.convert_to_tensor(np.array([[ -0.7082019, 110.77128  , -27.845854 ]], dtype=\"float32\"))),\n",
        "                'b1': tf.get_variable(\"b1\", initializer = tf.convert_to_tensor(np.array([[-2.8216890e-01],\n",
        "                [-4.620715e-03],\n",
        "                [-5.049001e+00]], dtype=\"float32\"))),\n",
        "                'b2': tf.get_variable(\"b2\", initializer = tf.convert_to_tensor(np.array([[0.98699754]], dtype=\"float32\")))}\n",
        "    '''\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e51YZob6bgm4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "   \n",
        "    Z1 = tf.add(tf.matmul(W1,X), b1)                                              # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2,A1), b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
        "    #A2 = tf.nn.sigmoid(Z2)                                           #final layer use sigmoid as only 2 classes \"Can't See\" or \"Can See\"\n",
        "    \n",
        "    return Z2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQg0sNh-Hp8v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(AL, Y, params):\n",
        "    \"\"\"\n",
        "    Implement the cost function defined by equation (7).\n",
        "\n",
        "    Arguments:\n",
        "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
        "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
        "\n",
        "    Returns:\n",
        "    cost -- cross-entropy cost\n",
        "    \"\"\"\n",
        "    labels = tf.transpose(Y)\n",
        "    logits = tf.transpose(AL)\n",
        "    beta = 0\n",
        "    #m = Y.shape[1]\n",
        "    # Compute loss from aL and y.\n",
        "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "    #cost = tf.divide(tf.reduce_sum(tf.add(tf.matmul(Y,tf.log(tf.transpose(AL))), tf.matmul(tf.subtract(1.0,Y),tf.log(tf.subtract(1.0,tf.transpose(AL))))), tf.multiply(-1.0, m)))\n",
        "   \n",
        "    cost = tf.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "    \n",
        "    regularizers = tf.squeeze(tf.nn.l2_loss(tf.squeeze(params[\"W1\"])) + tf.nn.l2_loss(tf.squeeze(params[\"W2\"])))\n",
        "    cost = tf.squeeze(tf.reduce_mean(cost + beta * regularizers))\n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g90vxfeRIETs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
        "    mini_batch_size -- size of the mini-batches, integer\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "        \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k*mini_batch_size : (k*mini_batch_size) + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size : (k*mini_batch_size) + mini_batch_size]\n",
        "\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        filled_egs = num_complete_minibatches * mini_batch_size\n",
        "        mini_batch_X = shuffled_X[:, filled_egs :]\n",
        "        mini_batch_Y = shuffled_Y[:, filled_egs :]\n",
        "      \n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAh52lS1IWCV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1000, minibatch_size = 20, print_cost = True): \n",
        "    \"\"\"\n",
        "    starting LR = 0.0001\n",
        "    lambda values 0.01, 0.02, ....\n",
        "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set, of shape (input size = 4, number of training examples = 37587)\n",
        "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_epochs -- number of epochs of the optimization loop\n",
        "    minibatch_size -- size of a minibatch\n",
        "    print_cost -- True to print the cost every 100 epochs\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    tf.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                            # n_y : output size\n",
        "    costs = []                                        # To keep track of the cost\n",
        "    \n",
        "  \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "\n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters()\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    cost = compute_cost(Z3, Y, parameters)\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "               \n",
        "                \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "             \n",
        "           \n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "                #parameters = sess.run(parameters)\n",
        "                Z3_sigmoid = tf.nn.sigmoid(Z3)\n",
        "                prediction = np.where(np.array(Z3_sigmoid.eval({X:X_train})) <= 0.5, 0.0, 1.0)\n",
        "                correct_prediction = tf.equal(np.float32(prediction), Y)\n",
        "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "                print (\"Train Accuracy:\", accuracy.eval({X:X_train, Y:Y_train}))\n",
        "                \n",
        "                \n",
        "                prediction = np.where(np.array(Z3_sigmoid.eval({X:X_test})) <= 0.5, 0.0, 1.0)\n",
        "                correct_prediction = tf.equal(np.float32(prediction), Y)\n",
        "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "                print(\"Test Accuray:\", accuracy.eval({X:X_test, Y:Y_test}))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "            \n",
        "\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "        parameters = sess.run(parameters)\n",
        "        '''\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        '''\n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UaJXMi-kKrJF",
        "colab_type": "code",
        "outputId": "d67b7d02-8cae-4e6e-c4b3-e69fb7db813b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        }
      },
      "cell_type": "code",
      "source": [
        "params = model(X_train, Y_train, X_test, Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 0.654548\n",
            "Train Accuracy: 0.6550935\n",
            "Test Accuray: 0.6570889\n",
            "Cost after epoch 100: 0.027087\n",
            "Train Accuracy: 0.9934552\n",
            "Test Accuray: 0.9933488\n",
            "Cost after epoch 200: 0.015778\n",
            "Train Accuracy: 0.9958496\n",
            "Test Accuray: 0.9953175\n",
            "Cost after epoch 300: 0.011894\n",
            "Train Accuracy: 0.996701\n",
            "Test Accuray: 0.9961955\n",
            "Cost after epoch 400: 0.009839\n",
            "Train Accuracy: 0.99717987\n",
            "Test Accuray: 0.9967276\n",
            "Cost after epoch 500: 0.008726\n",
            "Train Accuracy: 0.99779177\n",
            "Test Accuray: 0.9972863\n",
            "Cost after epoch 600: 0.007594\n",
            "Train Accuracy: 0.99805784\n",
            "Test Accuray: 0.99755234\n",
            "Cost after epoch 700: 0.006898\n",
            "Train Accuracy: 0.99824405\n",
            "Test Accuray: 0.99771196\n",
            "Cost after epoch 800: 0.006332\n",
            "Train Accuracy: 0.9985367\n",
            "Test Accuray: 0.99795145\n",
            "Cost after epoch 900: 0.005908\n",
            "Train Accuracy: 0.9986165\n",
            "Test Accuray: 0.9980046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhKKQGIiKSUEoCISEr9fyGfSyuhIKkLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff6ed286c50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "j3yjEn8gKz9w",
        "colab_type": "code",
        "outputId": "7d5cdc39-057e-490d-894c-f5fd181dacd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "print(params)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'W1': array([[  3.9428747 ,  11.59308   ,   1.8363051 , -16.980663  ],\n",
            "       [  2.668514  ,   3.8103638 ,   0.84936374,  -1.9624231 ],\n",
            "       [  0.22013244,  -1.5614797 ,   1.0716099 ,   4.961385  ]],\n",
            "      dtype=float32), 'b1': array([[-0.38128474],\n",
            "       [-3.9973104 ],\n",
            "       [-0.08543456]], dtype=float32), 'W2': array([[ 23.99707  , -17.736904 ,   4.3511972]], dtype=float32), 'b2': array([[-6.6498837]], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jrYzZumJHhBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''rams = {'W1': np.array([[ 1, 2 ,  3, 4 ],\n",
        "       [ 5,  6,  7, 8],\n",
        "       [ 9,  10 ,  11, 12]], dtype=\"float32\"), 'b1': np.array([[1],\n",
        "       [1 ],\n",
        "       [1 ]], dtype=\"float32\"), 'W2': np.array([[ 1,  2, 3]], dtype=\"float32\"), 'b2': np.array([[1]], dtype=\"float32\")} '''\n",
        "params = {'W1': np.array([[  3.9428747 ,  11.59308   ,   1.8363051 , -16.980663  ],\n",
        "       [  2.668514  ,   3.8103638 ,   0.84936374,  -1.9624231 ],\n",
        "       [  0.22013244,  -1.5614797 ,   1.0716099 ,   4.961385  ]],\n",
        "      dtype=\"float32\"), 'b1': np.array([[-0.38128474],\n",
        "       [-3.9973104 ],\n",
        "       [-0.08543456]], dtype=\"float32\"), 'W2': np.array([[ 23.99707  , -17.736904 ,   4.3511972]], dtype=\"float32\"), 'b2': np.array([[-6.6498837]], dtype=\"float32\")}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "htkSB7I8H8Rk",
        "colab_type": "code",
        "outputId": "0ae9af3d-2baf-4651-97bf-215c744f5721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "a = np.array([[252,255,94,1]], dtype=\"float32\")\n",
        "\n",
        "a[:,0:3] = a[:,0:3] / 256\n",
        "\n",
        "Z3 = forward_propagation(a.T,params)\n",
        "\n",
        "Z3_sigmoid = tf.nn.sigmoid(Z3)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  #prediction = np.where(np.array(sess.run(Z3_sigmoid)) <= 0.5, 0, 1)\n",
        "  print(sess.run(Z3_sigmoid))\n",
        "  print(sess.run(Z3))\n",
        "  #correct_prediction = tf.equal(prediction, Y_dev)\n",
        "  #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  #print (\"Dev Accuracy:\", accuracy.eval())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.03617267]]\n",
            "[[-3.2826083]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zp1p-aTpJORU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}